# Настроить централизованный сбор логов в ELK

# Полезная информация 

# Фильтрация логов 

cat syslog | grep err | grep -P '\d{2}:\d{}:00'

# последние 10 строк лога

tail -n 10 syslog

# первые 10 строк лога

head -n 10 syslog

# просмотр сообщений в реальном времени

tail -f syslog

# работа с  journald

# проверка формата времени

timedatectl status

sudo timedatectl set-timezone zone

# логи с момента загрузки

journalctl -b

# сохранение логов между загрузками системы

mkdir -p /var/log/journal

nano /etc/systemd/journal.conf

[Journal]
storage=persistent

# фильтрация по времени --since (от какой даты\время) --until (по какую дату\время)

journalctl --since "2025-01-01 15:00:00"

journalctl --since "2025-01-01 15:00:00" --until "2025-01-02 15:00:00"

journalctl --since yesterday

journalctl --since 9:00 --until "1 hour ago"

# фильтрация по юниту

journalctl -u nginx.service

# фильтрация по приоритету

journalctl -p err -b

# форматирование в JSON (показывает подробные лог вместо обычного)

journalctl -b -u nginx -o json-pretty

===========================================================================
# 1. установить Elasticsearch, Logstash, Kibana

# установка явы

apt install default-jdk -y

# Качаем пакеты (или используем репозиторий), важно чтобы все пакеты были одной версии

https://www.elastic.co/guide/en/elasticsearch/reference/8.9/deb.html

https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.9.1-amd64.deb

https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-8.9.1-amd64.deb

https://artifacts.elastic.co/downloads/kibana/kibana-8.9.1-amd64.deb

https://artifacts.elastic.co/downloads/beats/metricbeat/metricbeat-8.9.1-amd64.deb

https://artifacts.elastic.co/downloads/logstash/logstash-8.9.1-amd64.deb

https://artifacts.elastic.co/downloads/beats/packetbeat/packetbeat-8.9.1-amd64.deb

mkdir /home/sentsov/mount

chown sentsov:sentsov /home/sentsov/mount

mount -t vboxsf mount /home/sentsov/mount

cd mount

![alt text](image.png)

dpkg -i *.deb

# 2. настроить ELK Stack

# Устанавливаем лимиты памяти (1G) для виртуальной машины Java 

cat > /etc/elasticsearch/jvm.options.d/jvm.options

-Xms1g
-Xmx1g

ctrl+c

# Конфигурация ES

nano /etc/elasticsearch/elasticsearch.yml

# редактируем конфиг следующим образом

path.data: /var/lib/elasticsearch

path.logs: /var/log/elasticsearch

xpack.security.enabled: false

xpack.security.enrollment.enabled: true

xpack.security.http.ssl:
  enabled: false
  keystore.path: certs/http.p12

xpack.security.transport.ssl:
  enabled: false
  verification_mode: certificate
  keystore.path: certs/transport.p12
  truststore.path: certs/transport.p12
cluster.initial_master_nodes: ["elk"]

http.host: 0.0.0.0

#
ctrl+x

yes 

enter

# Старт сервиса

sudo systemctl daemon-reload

sudo systemctl enable --now elasticsearch.service

# Проверяем работу

curl http://localhost:9200

![alt text](image-1.png)

# Настройка kibana (если не установили как мы ранее, то dpkg -i kibana-8.9.1-amd64.deb)

# редактируем конфиг кибана, разкомментируем

nano /etc/kibana/kibana.yml

# --------------- Разкомментируем строку сервер порт и меняем в сервер хост на 0.0.0.0

server.port: 5601

server.host: "0.0.0.0"

# ---------------

ctrl+x

y

enter

# перегружаем кибана и запускаем службу

systemctl restart kibana

systemctl enable --now kibana.service

# Настройка Logstash (если не устанавливали как мы ранее, то dpkg -i logstash-8.9.1-amd64.deb)

systemctl enable --now logstash.service

# редактируем logstash config

nano /etc/logstash/logstash.yml

# после path.config: пишем в следующей строке

path.config: /etc/logstash/conf.d

ctrl+x

y

enter

# далее заливаем конфиг logstash для обработки логов nginx

cat > /etc/logstash/conf.d/logstash-nginx-es.conf

# тело конфига ------
input {
    beats {
        port => 5400
    }
}

filter {
 grok {
   match => [ "message" , "%{COMBINEDAPACHELOG}+%{GREEDYDATA:extra_fields}"]
   overwrite => [ "message" ]
 }
 mutate {
   convert => ["response", "integer"]
   convert => ["bytes", "integer"]
   convert => ["responsetime", "float"]
 }
 date {
   match => [ "timestamp" , "dd/MMM/YYYY:HH:mm:ss Z" ]
   remove_field => [ "timestamp" ]
 }
 useragent {
   source => "agent"
 }
}

output {
 elasticsearch {
   hosts => ["http://localhost:9200"]
   #cacert => '/etc/logstash/certs/http_ca.crt'
   #ssl => true
   index => "weblogs-%{+YYYY.MM.dd}"
   document_type => "nginx_logs"
 }
 stdout { codec => rubydebug }
}
# конец конфига-----------

ctrl+c

systemctl restart logstash.service

# Настройка filebeat (если не устнавливали как мы ранее, то dpkg -i filebeat-8.9.1-amd64.deb) 

nano /etc/filebeat/filebeat.yml

# редактируем конфиг
# в filebeat.inputs:   (комментим все и в конце вставляем):

- type: filestream
  paths:
    - /var/log/nginx/*.log

  enabled: true
  exclude_files: ['.gz$']
  prospector.scanner.exclude_files: ['.gz$']

# в разделе Elasticsearch Output закомментарить output.elasticsearch и  hosts: ["localhost:9200"]

# в  Logstash Output добавляем

output.logstash:
  hosts: ["localhost:5400"]

ctrl+x
y
enter

systemctl restart filebeat

![alt text](image-2.png)

# проверяем что у нас запущено

ss -ntlp

tail -n 20 /var/log/elasticsearch/elasticsearch.log

tail -n 20 /var/log/logstash/logstash-plain.log

tail -n 20 /var/log/kibana/kibana.log

filebeat modules enable nginx

# Заходим на веб 192.168.106.98:5601 и настраиваем

![alt text](image-4.png)



# 3. настроить сбор лога с web-сервера nginx
